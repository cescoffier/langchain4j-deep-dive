quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true

quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}

quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
quarkus.langchain4j.openai.chat-model.temperature=0.3
quarkus.langchain4j.openai.chat-model.max-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0

quarkus.langchain4j.pgvector.dimension=384
rag.location=src/main/resources/rag
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.onnx.bgesmallenq.BgeSmallEnQuantizedEmbeddingModel

quarkus.langchain4j.tavily.api-key=${TAVILY_API_KEY}
quarkus.langchain4j.tavily.max-results=3
quarkus.langchain4j.tavily.include-answer=true
quarkus.langchain4j.tavily.include-domains=quarkus.io
#quarkus.langchain4j.tavily.include-raw-content=true
quarkus.langchain4j.tavily.search-depth=advanced

quarkus.langchain4j.cohere.api-key=${COHERE_API_KEY}
quarkus.langchain4j.cohere.scoring-model.model-name=rerank-english-v3.0

%test.quarkus.langchain4j.log-requests=true
%test.quarkus.langchain4j.log-responses=true
%test,ollama.quarkus.langchain4j.openai.chat-model.model-name=llama3.2
%test,ollama.quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
%test,ollama.quarkus.langchain4j.openai.timeout=10m
%ollama.quarkus.langchain4j.openai.api-key=somesupersecretkey
%test.quarkus.tls.trust-all=true