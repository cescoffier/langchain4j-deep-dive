quarkus.langchain4j.timeout=60s
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true

quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# mailer config
quarkus.mailer.from=demoer@langchain4j.ai
quarkus.mailer.tls=false
%dev.quarkus.mailer.mock=false

# observability config
quarkus.otel.logs.enabled=true

%test.quarkus.langchain4j.log-requests=true
%test.quarkus.langchain4j.log-responses=true
%test,ollama.quarkus.langchain4j.openai.chat-model.model-name=llama3.2
%test,ollama.quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
%test,ollama.quarkus.langchain4j.openai.timeout=10m
%ollama.quarkus.langchain4j.openai.api-key=somesupersecretkey
%test.quarkus.tls.trust-all=true
%test.quarkus.observability.enabled=false
%test.quarkus.otel.logs.enabled=false
%test.quarkus.micrometer.export.otlp.enabled=${%test.quarkus.observability.enabled}
quarkus.http.test-port=-1