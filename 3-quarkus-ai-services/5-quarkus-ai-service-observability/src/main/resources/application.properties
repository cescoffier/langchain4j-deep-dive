quarkus.langchain4j.timeout=60s
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o

# observability config
quarkus.otel.logs.enabled=true

%test.quarkus.langchain4j.log-requests=true
%test.quarkus.langchain4j.log-responses=true
%test,ollama.quarkus.langchain4j.openai.chat-model.model-name=llama3.2
%test,ollama.quarkus.langchain4j.openai.base-url=http://localhost:11434/v1
%test,ollama.quarkus.langchain4j.openai.timeout=10m
%ollama.quarkus.langchain4j.openai.api-key=somesupersecretkey
%test.quarkus.observability.enabled=false
quarkus.http.test-port=-1
